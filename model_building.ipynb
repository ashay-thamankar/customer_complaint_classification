{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77cde275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\d drive\\py_practice\\venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\d drive\\py_practice\\venv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\d drive\\py_practice\\venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: spacy in c:\\d drive\\py_practice\\venv\\lib\\site-packages (3.8.11)\n",
      "Requirement already satisfied: nltk in c:\\d drive\\py_practice\\venv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: xgboost in c:\\d drive\\py_practice\\venv\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: wordcloud in c:\\d drive\\py_practice\\venv\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (0.20.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (2.12.4)\n",
      "Requirement already satisfied: jinja2 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (63.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: pillow in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from wordcloud) (12.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from wordcloud) (3.10.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from jinja2->spacy) (3.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from matplotlib->wordcloud) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from matplotlib->wordcloud) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\d drive\\py_practice\\venv\\lib\\site-packages (from matplotlib->wordcloud) (3.2.5)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 20.2 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 23.1 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 10.5/12.8 MB 23.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 11.3/12.8 MB 13.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 14.1 MB/s  0:00:00\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn spacy nltk xgboost wordcloud\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e702ce",
   "metadata": {},
   "source": [
    "# Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068bc7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, string\n",
    "import spacy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d84bb7",
   "metadata": {},
   "source": [
    "# Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32336321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded. Shape: (78313, 22)\n",
      "Text cleaning complete.\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "try:\n",
    "    f = open('complaints-2021-05-14_08_16.json')\n",
    "    data = json.load(f)\n",
    "    df = pd.json_normalize(data)\n",
    "    print(f\"Data Loaded. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'complaints-2021-05-14_08_16.json' not found. Please check the path.\")\n",
    "\n",
    "# Rename columns for easier access\n",
    "df.rename(columns={'_source.complaint_what_happened': 'complaint_text', \n",
    "                   '_source.product': 'product'}, inplace=True)\n",
    "\n",
    "# Filter out blank complaints\n",
    "df = df[df['complaint_text'].astype(bool)] # Removes empty strings\n",
    "df = df[df['complaint_text'] != \"\"]\n",
    "\n",
    "# Text Cleaning Function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Lemmatization\n",
    "    doc = nlp(text)\n",
    "    lemmatized = \" \".join([token.lemma_ for token in doc if token.pos_ in ['NOUN', 'PROPN']])\n",
    "    return lemmatized.strip()\n",
    "\n",
    "df['cleaned_complaint'] = df['complaint_text'].apply(clean_text)\n",
    "print(\"Text cleaning complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab219ef",
   "metadata": {},
   "source": [
    "# Feature Extraction & Topic Modelling (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f7d63da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "dtm = tfidf.fit_transform(df['cleaned_complaint'])\n",
    "\n",
    "# NMF Decomposition (5 Topics)\n",
    "num_topics = 5\n",
    "nmf_model = NMF(n_components=num_topics, random_state=40)\n",
    "nmf_model.fit(dtm)\n",
    "\n",
    "# Assign Topics to Documents\n",
    "topic_results = nmf_model.transform(dtm)\n",
    "df['topic_id'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45708e54",
   "metadata": {},
   "source": [
    "# Manual Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fffd9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOPIC 0 Top Words:\n",
      "['xxxxxxxxxxxx', 'company', 'address', 'document', 'letter', 'information', 'debt', 'complaint', 'phone', 'email', 'money', 'number', 'bank', 'chase', 'xxxx']\n",
      "\n",
      "TOPIC 1 Top Words:\n",
      "['letter', 'debt', 'information', 'year', 'application', 'limit', 'company', 'balance', 'score', 'account', 'chase', 'inquiry', 'report', 'card', 'credit']\n",
      "\n",
      "TOPIC 2 Top Words:\n",
      "['balance', 'customer', 'transaction', 'business', 'day', 'branch', 'fee', 'checking', 'deposit', 'fund', 'money', 'chase', 'check', 'bank', 'account']\n",
      "\n",
      "TOPIC 3 Top Words:\n",
      "['auto', 'statement', 'fee', 'rate', 'balance', 'time', 'year', 'xxxxxxxx', 'home', 'modification', 'month', 'chase', 'mortgage', 'loan', 'payment']\n",
      "\n",
      "TOPIC 4 Top Words:\n",
      "['day', 'service', 'fee', 'letter', 'statement', 'purchase', 'fraud', 'claim', 'merchant', 'card', 'transaction', 'dispute', 'chase', 'charge', 'xxxxxxxx']\n",
      "\n",
      "Labels assigned. Sample:\n",
      "                                    cleaned_complaint  \\\n",
      "1   morning name xxxx xxxx stop bank cardmember se...   \n",
      "2   xxxx xxxx card agent anniversary date agent in...   \n",
      "10  chase card application identity consent servic...   \n",
      "11  xxxx xxxx ticket offer ticket reward card info...   \n",
      "14  son check chase account fund chase bank accoun...   \n",
      "\n",
      "                   Topic_Label  \n",
      "1        Bank account services  \n",
      "2              Mortgages/loans  \n",
      "10  Credit card / Prepaid card  \n",
      "11  Credit card / Prepaid card  \n",
      "14                      Others  \n"
     ]
    }
   ],
   "source": [
    "# Print Top 15 words for each topic\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "for index, topic in enumerate(nmf_model.components_):\n",
    "    print(f\"\\nTOPIC {index} Top Words:\")\n",
    "    print([feature_names[i] for i in topic.argsort()[-15:]])\n",
    "\n",
    "topic_mapping = {\n",
    "    0: 'Bank account services',      \n",
    "    1: 'Credit card / Prepaid card', \n",
    "    2: 'Others',                     \n",
    "    3: 'Theft/Dispute reporting',    \n",
    "    4: 'Mortgages/loans'             \n",
    "}\n",
    "\n",
    "df['Topic_Label'] = df['topic_id'].map(topic_mapping)\n",
    "print(\"\\nLabels assigned. Sample:\")\n",
    "print(df[['cleaned_complaint', 'Topic_Label']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa93dc",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c43be29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 7 models...\n",
      "\n",
      "Logistic Regression F1 Score: 0.9549\n",
      "Decision Tree F1 Score: 0.8159\n",
      "Random Forest F1 Score: 0.8432\n",
      "AdaBoost F1 Score: 0.7781\n",
      "Gradient Boosting F1 Score: 0.9216\n",
      "XGBoost F1 Score: 0.9299\n",
      "Naive Bayes F1 Score: 0.7021\n",
      "\n",
      "------------------------------------------------\n",
      "WINNER: Logistic Regression with F1 Score: 0.9549\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define X and y\n",
    "X = dtm # The TF-IDF matrix\n",
    "y = df['topic_id']\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=40)\n",
    "\n",
    "# Dictionary of Classifiers\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(solver='liblinear'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    \"Naive Bayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "def evaluate_models(X_train, y_train, X_test, y_test, models):\n",
    "    model_report = {}\n",
    "    print(f\"Training {len(models)} models...\\n\")\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        model_report[model_name] = score\n",
    "        print(f\"{model_name} F1 Score: {score:.4f}\")\n",
    "        \n",
    "    return model_report, models\n",
    "\n",
    "# Run Evaluation\n",
    "report, trained_models = evaluate_models(X_train, y_train, X_test, y_test, models)\n",
    "\n",
    "# Select Best Model\n",
    "best_score = max(report.values())\n",
    "best_model_name = max(report, key=report.get)\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"\\n------------------------------------------------\")\n",
    "print(f\"WINNER: {best_model_name} with F1 Score: {best_score:.4f}\")\n",
    "print(f\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ec9800",
   "metadata": {},
   "source": [
    "# Final Inference (Prediction System)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1c276b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Complaint: I applied for a loan to buy a house but the interest rate was different from what was promised.\n",
      "Predicted Department: Theft/Dispute reporting\n"
     ]
    }
   ],
   "source": [
    "def predict_complaint_category(text):\n",
    "    # Clean the text\n",
    "    clean_text_input = clean_text(text)\n",
    "    \n",
    "    # Transform using the fitted TF-IDF\n",
    "    vectorized_input = tfidf.transform([clean_text_input])\n",
    "    \n",
    "    # Predict using the best model\n",
    "    prediction_id = best_model.predict(vectorized_input)[0]\n",
    "    \n",
    "    # Map ID back to Category Name\n",
    "    category_name = topic_mapping[prediction_id]\n",
    "    \n",
    "    return category_name\n",
    "\n",
    "sample_complaint = \"I applied for a loan to buy a house but the interest rate was different from what was promised.\"\n",
    "result = predict_complaint_category(sample_complaint)\n",
    "\n",
    "print(f\"Input Complaint: {sample_complaint}\")\n",
    "print(f\"Predicted Department: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
